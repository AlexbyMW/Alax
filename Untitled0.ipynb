{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BU_9DLvmLCVJ-uh1vVNS6JXX7dnKBsOq",
      "authorship_tag": "ABX9TyMNUMAdLa3Kp1jbgVMCCODn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexbyMW/Alax/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ug4Jkq3VN7h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "f5d4FutwaUWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive');\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab');\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn;\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data();\n",
        "from sklearn.model_selection import train_test_split;\n",
        "\n",
        "X = np.concatenate((X_train, X_test))\n",
        "y = np.concatenate((y_train, y_test));\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                        test_size = 10000,\n",
        "                                        train_size = 60000,\n",
        "                                        random_state = 123);\n",
        "print('Shape of X train:', X_train.shape)\n",
        "print('Shape of y train:', y_train.shape);\n",
        "\n",
        "plt.imshow(X_train[123], cmap=plt.get_cmap('gray'))\n",
        "plt.show();\n",
        "print(y_train[123]);\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels) / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels) / 255\n",
        "print('Shape of transformed X train:', X_train.shape);\n",
        "\n",
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "print('Shape of transformed y train:', y_train.shape)\n",
        "num_classes = y_train.shape[1];\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense;\n",
        "model = Sequential()\n",
        "model.add(Dense(units=300, input_dim=num_pixels, activation='sigmoid'))\n",
        "model.add(Dense(units=100, activation='sigmoid'));\n",
        "model.add(Dense(units=num_classes, activation='softmax'));\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']);\n",
        "print(model.summary());\n",
        "H = model.fit(X_train, y_train, validation_split=0.1, epochs=100);\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.grid()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.title('Loss by epochs')\n",
        "plt.show();\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print('Loss on test data:', scores[0])\n",
        "print('Accuracy on test data:', scores[1]);\n",
        "n = 123\n",
        "result = model.predict(X_test[n:n+1])\n",
        "print('NN output:', result)\n",
        "plt.imshow(X_test[n].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "print('Real mark: ', str(np.argmax(y_test[n])))\n",
        "print('NN answer: ', str(np.argmax(result)));\n",
        "from PIL import Image\n",
        "file_data = Image.open('test.png')\n",
        "file_data = file_data.convert('L')\n",
        "test_img = np.array(file_data);\n",
        "plt.imshow(test_img, cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "test_img = test_img / 255\n",
        "test_img = test_img.reshape(1, num_pixels)\n",
        "result = model.predict(test_img)\n",
        "print('I think it\\'s ', np.argmax(result));"
      ],
      "metadata": {
        "id": "I_H8ELSzVQzU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "150a1ad8-54dc-4829-ae96-bb2f5ed8e768"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Shape of X train: (60000, 28, 28)\n",
            "Shape of y train: (60000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Shape of transformed X train: (60000, 784)\n",
            "Shape of transformed y train: (60000, 10)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 5s 2ms/step - loss: 2.1655 - accuracy: 0.3997 - val_loss: 1.9623 - val_accuracy: 0.5670\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 1.5884 - accuracy: 0.6719 - val_loss: 1.2210 - val_accuracy: 0.7443\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.9801 - accuracy: 0.7797 - val_loss: 0.8071 - val_accuracy: 0.7928\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.7060 - accuracy: 0.8293 - val_loss: 0.6278 - val_accuracy: 0.8425\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5755 - accuracy: 0.8536 - val_loss: 0.5326 - val_accuracy: 0.8635\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.5001 - accuracy: 0.8691 - val_loss: 0.4756 - val_accuracy: 0.8715\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4512 - accuracy: 0.8793 - val_loss: 0.4344 - val_accuracy: 0.8847\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4177 - accuracy: 0.8865 - val_loss: 0.4062 - val_accuracy: 0.8900\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3933 - accuracy: 0.8919 - val_loss: 0.3860 - val_accuracy: 0.8937\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3751 - accuracy: 0.8956 - val_loss: 0.3720 - val_accuracy: 0.8985\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3605 - accuracy: 0.8994 - val_loss: 0.3584 - val_accuracy: 0.9005\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3487 - accuracy: 0.9020 - val_loss: 0.3494 - val_accuracy: 0.9038\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3388 - accuracy: 0.9041 - val_loss: 0.3404 - val_accuracy: 0.9062\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3304 - accuracy: 0.9064 - val_loss: 0.3331 - val_accuracy: 0.9067\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3231 - accuracy: 0.9081 - val_loss: 0.3258 - val_accuracy: 0.9092\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3163 - accuracy: 0.9097 - val_loss: 0.3194 - val_accuracy: 0.9123\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3106 - accuracy: 0.9105 - val_loss: 0.3159 - val_accuracy: 0.9120\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3053 - accuracy: 0.9122 - val_loss: 0.3107 - val_accuracy: 0.9130\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3000 - accuracy: 0.9135 - val_loss: 0.3062 - val_accuracy: 0.9143\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2954 - accuracy: 0.9150 - val_loss: 0.3031 - val_accuracy: 0.9153\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2913 - accuracy: 0.9164 - val_loss: 0.2972 - val_accuracy: 0.9168\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2872 - accuracy: 0.9172 - val_loss: 0.2947 - val_accuracy: 0.9177\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2834 - accuracy: 0.9186 - val_loss: 0.2914 - val_accuracy: 0.9170\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2798 - accuracy: 0.9199 - val_loss: 0.2879 - val_accuracy: 0.9183\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2762 - accuracy: 0.9203 - val_loss: 0.2853 - val_accuracy: 0.9205\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2730 - accuracy: 0.9213 - val_loss: 0.2814 - val_accuracy: 0.9207\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2697 - accuracy: 0.9218 - val_loss: 0.2794 - val_accuracy: 0.9210\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.9223 - val_loss: 0.2758 - val_accuracy: 0.9215\n",
            "Epoch 29/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2636 - accuracy: 0.9239 - val_loss: 0.2734 - val_accuracy: 0.9212\n",
            "Epoch 30/100\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2608 - accuracy: 0.9246 - val_loss: 0.2734 - val_accuracy: 0.9218\n",
            "Epoch 31/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2578 - accuracy: 0.9251 - val_loss: 0.2671 - val_accuracy: 0.9223\n",
            "Epoch 32/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2552 - accuracy: 0.9259 - val_loss: 0.2663 - val_accuracy: 0.9235\n",
            "Epoch 33/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2526 - accuracy: 0.9266 - val_loss: 0.2627 - val_accuracy: 0.9248\n",
            "Epoch 34/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2498 - accuracy: 0.9269 - val_loss: 0.2602 - val_accuracy: 0.9253\n",
            "Epoch 35/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2473 - accuracy: 0.9283 - val_loss: 0.2590 - val_accuracy: 0.9247\n",
            "Epoch 36/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2448 - accuracy: 0.9285 - val_loss: 0.2572 - val_accuracy: 0.9245\n",
            "Epoch 37/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2423 - accuracy: 0.9299 - val_loss: 0.2530 - val_accuracy: 0.9273\n",
            "Epoch 38/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2397 - accuracy: 0.9304 - val_loss: 0.2511 - val_accuracy: 0.9260\n",
            "Epoch 39/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2373 - accuracy: 0.9308 - val_loss: 0.2497 - val_accuracy: 0.9282\n",
            "Epoch 40/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2347 - accuracy: 0.9319 - val_loss: 0.2489 - val_accuracy: 0.9265\n",
            "Epoch 41/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2325 - accuracy: 0.9328 - val_loss: 0.2456 - val_accuracy: 0.9282\n",
            "Epoch 42/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2301 - accuracy: 0.9334 - val_loss: 0.2427 - val_accuracy: 0.9292\n",
            "Epoch 43/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2277 - accuracy: 0.9343 - val_loss: 0.2414 - val_accuracy: 0.9298\n",
            "Epoch 44/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2254 - accuracy: 0.9348 - val_loss: 0.2392 - val_accuracy: 0.9300\n",
            "Epoch 45/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2231 - accuracy: 0.9356 - val_loss: 0.2366 - val_accuracy: 0.9308\n",
            "Epoch 46/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2207 - accuracy: 0.9363 - val_loss: 0.2347 - val_accuracy: 0.9313\n",
            "Epoch 47/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2186 - accuracy: 0.9367 - val_loss: 0.2315 - val_accuracy: 0.9320\n",
            "Epoch 48/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2164 - accuracy: 0.9369 - val_loss: 0.2291 - val_accuracy: 0.9333\n",
            "Epoch 49/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2142 - accuracy: 0.9380 - val_loss: 0.2278 - val_accuracy: 0.9333\n",
            "Epoch 50/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2119 - accuracy: 0.9387 - val_loss: 0.2277 - val_accuracy: 0.9330\n",
            "Epoch 51/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2099 - accuracy: 0.9391 - val_loss: 0.2240 - val_accuracy: 0.9348\n",
            "Epoch 52/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2076 - accuracy: 0.9396 - val_loss: 0.2236 - val_accuracy: 0.9352\n",
            "Epoch 53/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2055 - accuracy: 0.9401 - val_loss: 0.2219 - val_accuracy: 0.9345\n",
            "Epoch 54/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2033 - accuracy: 0.9408 - val_loss: 0.2179 - val_accuracy: 0.9353\n",
            "Epoch 55/100\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2014 - accuracy: 0.9415 - val_loss: 0.2157 - val_accuracy: 0.9365\n",
            "Epoch 56/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1992 - accuracy: 0.9428 - val_loss: 0.2150 - val_accuracy: 0.9367\n",
            "Epoch 57/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1973 - accuracy: 0.9431 - val_loss: 0.2135 - val_accuracy: 0.9373\n",
            "Epoch 58/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1953 - accuracy: 0.9434 - val_loss: 0.2106 - val_accuracy: 0.9387\n",
            "Epoch 59/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9440 - val_loss: 0.2091 - val_accuracy: 0.9385\n",
            "Epoch 60/100\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1913 - accuracy: 0.9448 - val_loss: 0.2070 - val_accuracy: 0.9383\n",
            "Epoch 61/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1895 - accuracy: 0.9453 - val_loss: 0.2060 - val_accuracy: 0.9375\n",
            "Epoch 62/100\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1873 - accuracy: 0.9459 - val_loss: 0.2044 - val_accuracy: 0.9392\n",
            "Epoch 63/100\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1856 - accuracy: 0.9467 - val_loss: 0.2021 - val_accuracy: 0.9418\n",
            "Epoch 64/100\n",
            " 394/1688 [======>.......................] - ETA: 2s - loss: 0.1749 - accuracy: 0.9493"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b90558965c4c>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}